{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/fishee82oo/nfs-oil-price-prediction/blob/main/GDELT_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Temporal GNN Training for Oil Price Prediction\n",
        "\n",
        "This notebook contains the full training workflow for predicting oil price changes from temporal graph snapshots. All dataset utilities, model definitions, and training helpers live here so you can run end-to-end experiments from a single place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment setup\n",
        "\n",
        "Install the required Python packages before running the rest of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Callable, List, Optional, Sequence, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torch_geometric.data import Batch, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GraphNorm, SAGEConv, global_mean_pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset utilities\n",
        "\n",
        "`GraphSnapshotDataset` loads snapshot metadata, enforces a 5\u201310 year training window, and materialises `torch_geometric.data.Data` objects on demand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\"\"\"Dataset helpers for temporal graph snapshots with oil price labels.\"\"\"\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class SnapshotMetadata:\n",
        "    \"\"\"Metadata describing a single graph snapshot.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    timestamp:\n",
        "        Datetime of the snapshot. Used to build temporal splits.\n",
        "    graph_path:\n",
        "        Path on disk pointing to a serialized :class:`~torch_geometric.data.Data`\n",
        "        object. ``torch.load`` will be used to materialise the object when the\n",
        "        dataset item is requested.\n",
        "    label:\n",
        "        Target value representing the observed oil price change aligned with the\n",
        "        graph snapshot. Regression targets are expected to be floats; however, it\n",
        "        is up to the caller to ensure the underlying data matches the learning\n",
        "        task.\n",
        "    extra:\n",
        "        Optional additional metadata loaded from the CSV file. Retained for\n",
        "        downstream logging/debugging without affecting training.\n",
        "    \"\"\"\n",
        "\n",
        "    timestamp: datetime\n",
        "    graph_path: Path\n",
        "    label: float\n",
        "    extra: dict\n",
        "\n",
        "\n",
        "class GraphSnapshotDataset(Dataset):\n",
        "    \"\"\"Graph dataset aligned with oil price changes.\n",
        "\n",
        "    The dataset expects a metadata CSV with at least three columns:\n",
        "\n",
        "    ``timestamp``\n",
        "        Datetime (ISO 8601, YYYY-MM-DD, or any pandas-compatible format)\n",
        "        indicating when the snapshot was recorded.\n",
        "    ``graph_path``\n",
        "        Path to a serialized :class:`torch_geometric.data.Data` object. Paths can\n",
        "        be absolute or relative to the CSV location.\n",
        "    ``price_change``\n",
        "        Numeric value representing the observed change in oil price for the\n",
        "        snapshot (target label).\n",
        "\n",
        "    Additional columns are preserved inside :class:`SnapshotMetadata.extra` for\n",
        "    logging or advanced filtering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        metadata_csv: Path | str,\n",
        "        *,\n",
        "        start_year: Optional[int] = None,\n",
        "        end_year: Optional[int] = None,\n",
        "        min_years: int = 5,\n",
        "        max_years: int = 10,\n",
        "        label_column: str = \"price_change\",\n",
        "        time_column: str = \"timestamp\",\n",
        "        graph_path_column: str = \"graph_path\",\n",
        "        transform: Optional[Callable[[Data], Data]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._metadata_path = Path(metadata_csv)\n",
        "        if not self._metadata_path.exists():\n",
        "            raise FileNotFoundError(f\"Metadata CSV not found: {self._metadata_path}\")\n",
        "\n",
        "        self.transform = transform\n",
        "        self._label_column = label_column\n",
        "        self._time_column = time_column\n",
        "        self._graph_column = graph_path_column\n",
        "\n",
        "        df = pd.read_csv(self._metadata_path)\n",
        "        if time_column not in df.columns:\n",
        "            raise ValueError(f\"Missing time column '{time_column}' in metadata\")\n",
        "        if graph_path_column not in df.columns:\n",
        "            raise ValueError(\n",
        "                f\"Missing graph path column '{graph_path_column}' in metadata\"\n",
        "            )\n",
        "        if label_column not in df.columns:\n",
        "            raise ValueError(f\"Missing label column '{label_column}' in metadata\")\n",
        "\n",
        "        df[time_column] = pd.to_datetime(df[time_column], utc=True, errors=\"coerce\")\n",
        "        if df[time_column].isna().any():\n",
        "            raise ValueError(\"Some timestamps could not be parsed. Ensure ISO-8601 format.\")\n",
        "\n",
        "        df = df.sort_values(time_column)\n",
        "        available_years = df[time_column].dt.year\n",
        "        min_available_year = int(available_years.min())\n",
        "        max_available_year = int(available_years.max())\n",
        "\n",
        "        if start_year is None and end_year is None:\n",
        "            end_year = max_available_year\n",
        "            start_year = max(min_available_year, end_year - max_years + 1)\n",
        "        elif start_year is None:\n",
        "            start_year = max(min_available_year, int(end_year) - max_years + 1)\n",
        "        elif end_year is None:\n",
        "            end_year = min(max_available_year, int(start_year) + max_years - 1)\n",
        "\n",
        "        if start_year > end_year:\n",
        "            raise ValueError(\n",
        "                f\"Invalid year range start={start_year}, end={end_year}. start must be <= end.\"\n",
        "            )\n",
        "\n",
        "        year_span = end_year - start_year + 1\n",
        "        if year_span < min_years:\n",
        "            raise ValueError(\n",
        "                \"Year range must span at least \"\n",
        "                f\"{min_years} years; received {year_span} years ({start_year}-{end_year}).\"\n",
        "            )\n",
        "        if year_span > max_years:\n",
        "            raise ValueError(\n",
        "                \"Year range must be within the configured maximum. \"\n",
        "                f\"Got {year_span} years, maximum allowed is {max_years}.\"\n",
        "            )\n",
        "\n",
        "        mask = (df[time_column].dt.year >= start_year) & (df[time_column].dt.year <= end_year)\n",
        "        df = df.loc[mask]\n",
        "        if df.empty:\n",
        "            raise ValueError(\n",
        "                \"No snapshots found for the requested time window. \"\n",
        "                f\"Available years: {min_available_year}-{max_available_year}.\"\n",
        "            )\n",
        "\n",
        "        base_dir = self._metadata_path.parent\n",
        "        metadata: List[SnapshotMetadata] = []\n",
        "        for row in df.itertuples(index=False):\n",
        "            timestamp = getattr(row, time_column)\n",
        "            label = float(getattr(row, label_column))\n",
        "            raw_graph_path = getattr(row, graph_path_column)\n",
        "            graph_path = (base_dir / raw_graph_path).resolve()\n",
        "            if not graph_path.exists():\n",
        "                raise FileNotFoundError(\n",
        "                    f\"Graph snapshot referenced in metadata does not exist: {graph_path}\"\n",
        "                )\n",
        "\n",
        "            extra = {\n",
        "                column: getattr(row, column)\n",
        "                for column in df.columns\n",
        "                if column not in {time_column, graph_path_column, label_column}\n",
        "            }\n",
        "            metadata.append(\n",
        "                SnapshotMetadata(\n",
        "                    timestamp=timestamp.to_pydatetime(),\n",
        "                    graph_path=graph_path,\n",
        "                    label=label,\n",
        "                    extra=extra,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if len(metadata) < 2:\n",
        "            raise ValueError(\"Dataset must contain at least two snapshots for training.\")\n",
        "\n",
        "        self._metadata = tuple(metadata)\n",
        "\n",
        "    @property\n",
        "    def start_timestamp(self) -> datetime:\n",
        "        return self._metadata[0].timestamp\n",
        "\n",
        "    @property\n",
        "    def end_timestamp(self) -> datetime:\n",
        "        return self._metadata[-1].timestamp\n",
        "\n",
        "    @property\n",
        "    def metadata(self) -> Sequence[SnapshotMetadata]:\n",
        "        return self._metadata\n",
        "\n",
        "    def __len__(self) -> int:  # type: ignore[override]\n",
        "        return len(self._metadata)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Data:  # type: ignore[override]\n",
        "        meta = self._metadata[index]\n",
        "        data = torch.load(meta.graph_path)\n",
        "        if not isinstance(data, Data):\n",
        "            raise TypeError(\n",
        "                f\"Snapshot at {meta.graph_path} is not a torch_geometric.data.Data object\"\n",
        "            )\n",
        "\n",
        "        y = torch.tensor([meta.label], dtype=torch.float)\n",
        "        data.y = y\n",
        "        data.snapshot_timestamp = meta.timestamp  # type: ignore[attr-defined]\n",
        "        data.snapshot_metadata = meta.extra  # type: ignore[attr-defined]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def split_indices(\n",
        "        self,\n",
        "        train_ratio: float = 0.7,\n",
        "        val_ratio: float = 0.15,\n",
        "        *,\n",
        "        shuffle_within_year: bool = False,\n",
        "        generator: Optional[torch.Generator] = None,\n",
        "    ) -> Tuple[List[int], List[int], List[int]]:\n",
        "        \"\"\"Create chronological splits for train/val/test.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        train_ratio, val_ratio:\n",
        "            Fractions of the dataset assigned to training and validation sets.\n",
        "            The remainder is assigned to the test set. Ratios refer to the number\n",
        "            of snapshots (not years) and will preserve chronological ordering.\n",
        "        shuffle_within_year:\n",
        "            When enabled, shuffles the order of snapshots captured in the same\n",
        "            calendar year before applying the split. This can help reduce bias if\n",
        "            multiple snapshots exist per year.\n",
        "        generator:\n",
        "            Optional random generator for deterministic shuffling.\n",
        "        \"\"\"\n",
        "\n",
        "        if train_ratio <= 0 or val_ratio < 0:\n",
        "            raise ValueError(\"train_ratio must be > 0 and val_ratio must be >= 0\")\n",
        "        if train_ratio + val_ratio >= 1:\n",
        "            raise ValueError(\"train_ratio + val_ratio must be < 1 to leave room for test\")\n",
        "\n",
        "        grouped_indices: List[int] = list(range(len(self._metadata)))\n",
        "        if shuffle_within_year:\n",
        "            grouped: dict[int, List[int]] = {}\n",
        "            for idx, meta in enumerate(self._metadata):\n",
        "                grouped.setdefault(meta.timestamp.year, []).append(idx)\n",
        "            grouped_indices = []\n",
        "            for year in sorted(grouped.keys()):\n",
        "                indices = grouped[year]\n",
        "                if generator is not None:\n",
        "                    perm = torch.randperm(len(indices), generator=generator).tolist()\n",
        "                    indices = [indices[i] for i in perm]\n",
        "                grouped_indices.extend(indices)\n",
        "\n",
        "        n_total = len(grouped_indices)\n",
        "        n_train = int(n_total * train_ratio)\n",
        "        n_val = int(n_total * val_ratio)\n",
        "        n_test = n_total - n_train - n_val\n",
        "        if n_train == 0 or n_val == 0 or n_test == 0:\n",
        "            raise ValueError(\n",
        "                \"Not enough samples to satisfy split ratios. \"\n",
        "                f\"Dataset size {n_total}, train {n_train}, val {n_val}, test {n_test}.\"\n",
        "            )\n",
        "\n",
        "        train_idx = grouped_indices[:n_train]\n",
        "        val_idx = grouped_indices[n_train : n_train + n_val]\n",
        "        test_idx = grouped_indices[n_train + n_val :]\n",
        "        return train_idx, val_idx, test_idx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics and training helpers\n",
        "\n",
        "Regression metrics, early stopping, and the epoch-level training loop live in this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class RegressionMetrics:\n",
        "    mae: float\n",
        "    rmse: float\n",
        "    r2: float\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainingHistoryEntry:\n",
        "    epoch: int\n",
        "    train_loss: float\n",
        "    val_loss: float\n",
        "    val_metrics: RegressionMetrics\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Simple early stopping helper.\"\"\"\n",
        "\n",
        "    def __init__(self, patience: int = 20, min_delta: float = 0.0) -> None:\n",
        "        if patience <= 0:\n",
        "            raise ValueError(\"patience must be > 0\")\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self._best_score: Optional[float] = None\n",
        "        self._best_state_dict: Optional[dict[str, torch.Tensor]] = None\n",
        "        self._counter = 0\n",
        "\n",
        "    @property\n",
        "    def best_state_dict(self) -> Optional[dict[str, torch.Tensor]]:\n",
        "        return self._best_state_dict\n",
        "\n",
        "    def step(self, score: float, model: nn.Module) -> bool:\n",
        "        if self._best_score is None or score < self._best_score - self.min_delta:\n",
        "            self._best_score = score\n",
        "            self._counter = 0\n",
        "            self._best_state_dict = {\n",
        "                k: v.detach().cpu().clone() for k, v in model.state_dict().items()\n",
        "            }\n",
        "            return False\n",
        "\n",
        "        self._counter += 1\n",
        "        return self._counter >= self.patience\n",
        "\n",
        "\n",
        "def compute_regression_metrics(\n",
        "    y_true: torch.Tensor, y_pred: torch.Tensor\n",
        ") -> RegressionMetrics:\n",
        "    if y_true.ndim > 1:\n",
        "        y_true = y_true.view(-1)\n",
        "    if y_pred.ndim > 1:\n",
        "        y_pred = y_pred.view(-1)\n",
        "\n",
        "    mae = torch.mean(torch.abs(y_true - y_pred)).item()\n",
        "    mse = torch.mean((y_true - y_pred) ** 2)\n",
        "    rmse = torch.sqrt(mse).item()\n",
        "\n",
        "    y_true_mean = torch.mean(y_true)\n",
        "    ss_tot = torch.sum((y_true - y_true_mean) ** 2)\n",
        "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
        "    if ss_tot == 0:\n",
        "        r2 = 0.0\n",
        "    else:\n",
        "        r2 = (1 - ss_res / ss_tot).item()\n",
        "\n",
        "    return RegressionMetrics(mae=mae, rmse=rmse, r2=r2)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    *,\n",
        "    device: Optional[torch.device] = None,\n",
        "    scheduler: Optional[torch.optim.lr_scheduler.ReduceLROnPlateau] = None,\n",
        "    max_epochs: int = 200,\n",
        "    early_stopping: Optional[EarlyStopping] = None,\n",
        ") -> List[TrainingHistoryEntry]:\n",
        "    \"\"\"Train a model, returning the epoch history.\"\"\"\n",
        "\n",
        "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    history: List[TrainingHistoryEntry] = []\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        model.train()\n",
        "        train_losses: List[float] = []\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(batch)\n",
        "            target = batch.y.to(device).view_as(preds)\n",
        "            loss = criterion(preds, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        mean_train_loss = float(torch.tensor(train_losses).mean().item()) if train_losses else 0.0\n",
        "\n",
        "        model.eval()\n",
        "        val_losses: List[float] = []\n",
        "        y_true: List[torch.Tensor] = []\n",
        "        y_pred: List[torch.Tensor] = []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                preds = model(batch)\n",
        "                target = batch.y.to(device).view_as(preds)\n",
        "                loss = criterion(preds, target)\n",
        "                val_losses.append(loss.item())\n",
        "                y_true.append(target.detach().cpu())\n",
        "                y_pred.append(preds.detach().cpu())\n",
        "\n",
        "        if not y_true or not y_pred:\n",
        "            raise ValueError(\"Validation loader produced no batches; cannot compute metrics.\")\n",
        "\n",
        "        mean_val_loss = float(torch.tensor(val_losses).mean().item()) if val_losses else 0.0\n",
        "        val_metrics = compute_regression_metrics(torch.cat(y_true), torch.cat(y_pred))\n",
        "        history.append(\n",
        "            TrainingHistoryEntry(\n",
        "                epoch=epoch,\n",
        "                train_loss=mean_train_loss,\n",
        "                val_loss=mean_val_loss,\n",
        "                val_metrics=val_metrics,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(mean_val_loss)\n",
        "\n",
        "        if early_stopping is not None:\n",
        "            should_stop = early_stopping.step(mean_val_loss, model)\n",
        "            if should_stop:\n",
        "                break\n",
        "\n",
        "    if early_stopping is not None and early_stopping.best_state_dict is not None:\n",
        "        model.load_state_dict(early_stopping.best_state_dict)\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph neural network architecture\n",
        "\n",
        "A lightweight GraphSAGE-based regressor with optional timestamp encoding summarises each snapshot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OilPriceTemporalGNNConfig:\n",
        "    input_channels: int\n",
        "    hidden_channels: int = 128\n",
        "    output_channels: int = 1\n",
        "    num_layers: int = 3\n",
        "    dropout: float = 0.2\n",
        "    use_timestamp_encoding: bool = True\n",
        "\n",
        "\n",
        "def _encode_timestamps(batch: Batch | Data) -> Optional[torch.Tensor]:\n",
        "    \"\"\"Return a ``(batch_size, 1)`` tensor with normalized timestamps if present.\"\"\"\n",
        "\n",
        "    timestamps = getattr(batch, \"snapshot_timestamp\", None)\n",
        "    if timestamps is None:\n",
        "        return None\n",
        "\n",
        "    if isinstance(timestamps, torch.Tensor):\n",
        "        ts_tensor = timestamps.float().view(-1, 1)\n",
        "    else:\n",
        "        if not isinstance(timestamps, (list, tuple)):\n",
        "            timestamps = [timestamps]\n",
        "        values = [torch.as_tensor(ts.timestamp(), dtype=torch.float) for ts in timestamps]\n",
        "        ts_tensor = torch.stack(values, dim=0).view(-1, 1)\n",
        "\n",
        "    ts_tensor = ts_tensor.to(batch.x.device if hasattr(batch, \"x\") else ts_tensor.device)\n",
        "    ts_mean = ts_tensor.mean()\n",
        "    ts_std = ts_tensor.std(unbiased=False)\n",
        "    if ts_std == 0:\n",
        "        ts_std = ts_std + 1.0\n",
        "    ts_tensor = (ts_tensor - ts_mean) / ts_std\n",
        "    return ts_tensor\n",
        "\n",
        "\n",
        "class OilPriceTemporalGNN(nn.Module):\n",
        "    \"\"\"A lightweight GraphSAGE-based model for oil price change prediction.\"\"\"\n",
        "\n",
        "    def __init__(self, config: OilPriceTemporalGNNConfig) -> None:\n",
        "        super().__init__()\n",
        "        if config.num_layers < 1:\n",
        "            raise ValueError(\"num_layers must be >= 1\")\n",
        "\n",
        "        self.config = config\n",
        "        layers = []\n",
        "        norms = []\n",
        "        in_channels = config.input_channels\n",
        "        for _ in range(config.num_layers):\n",
        "            conv = SAGEConv(in_channels, config.hidden_channels)\n",
        "            norm = GraphNorm(config.hidden_channels)\n",
        "            layers.append(conv)\n",
        "            norms.append(norm)\n",
        "            in_channels = config.hidden_channels\n",
        "\n",
        "        self.convs = nn.ModuleList(layers)\n",
        "        self.norms = nn.ModuleList(norms)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "        readout_dim = config.hidden_channels\n",
        "        if config.use_timestamp_encoding:\n",
        "            readout_dim += 1\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(readout_dim, config.hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.hidden_channels, config.output_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, batch: Batch | Data) -> torch.Tensor:\n",
        "        x, edge_index, batch_index = batch.x, batch.edge_index, batch.batch\n",
        "        for conv, norm in zip(self.convs, self.norms):\n",
        "            x = conv(x, edge_index)\n",
        "            x = norm(x, batch_index)\n",
        "            x = torch.relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        pooled = global_mean_pool(x, batch_index)\n",
        "        if self.config.use_timestamp_encoding:\n",
        "            ts_encoding = _encode_timestamps(batch)\n",
        "            if ts_encoding is not None:\n",
        "                ts_encoding = ts_encoding.to(pooled.device)\n",
        "                if ts_encoding.shape[0] != pooled.shape[0]:\n",
        "                    raise RuntimeError(\n",
        "                        \"Timestamp encoding size mismatch. Ensure each graph has a timestamp.\"\n",
        "                    )\n",
        "                pooled = torch.cat([pooled, ts_encoding], dim=1)\n",
        "        return self.regressor(pooled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End-to-end training helper\n",
        "\n",
        "Use `run_training` to load the dataset, train the model with early stopping, evaluate on the held-out test split, and optionally persist metrics to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def run_training(\n",
        "    metadata_csv: Path | str,\n",
        "    *,\n",
        "    start_year: Optional[int] = None,\n",
        "    end_year: Optional[int] = None,\n",
        "    min_years: int = 5,\n",
        "    max_years: int = 10,\n",
        "    train_ratio: float = 0.7,\n",
        "    val_ratio: float = 0.15,\n",
        "    batch_size: int = 32,\n",
        "    num_layers: int = 3,\n",
        "    hidden_channels: int = 128,\n",
        "    dropout: float = 0.2,\n",
        "    learning_rate: float = 1e-3,\n",
        "    weight_decay: float = 1e-4,\n",
        "    epochs: int = 200,\n",
        "    patience: int = 25,\n",
        "    min_delta: float = 1e-4,\n",
        "    disable_timestamp_encoding: bool = False,\n",
        "    num_workers: int = 0,\n",
        "    shuffle_within_year: bool = False,\n",
        "    output_dir: Optional[Path | str] = None,\n",
        ") -> tuple[list[dict], dict]:\n",
        "    dataset = GraphSnapshotDataset(\n",
        "        metadata_csv,\n",
        "        start_year=start_year,\n",
        "        end_year=end_year,\n",
        "        min_years=min_years,\n",
        "        max_years=max_years,\n",
        "    )\n",
        "\n",
        "    train_idx, val_idx, test_idx = dataset.split_indices(\n",
        "        train_ratio=train_ratio,\n",
        "        val_ratio=val_ratio,\n",
        "        shuffle_within_year=shuffle_within_year,\n",
        "    )\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    sample = dataset[0]\n",
        "    if sample.x is None:\n",
        "        raise ValueError(\"Graph snapshots must contain node features in `data.x`.\")\n",
        "\n",
        "    config = OilPriceTemporalGNNConfig(\n",
        "        input_channels=sample.num_node_features,\n",
        "        hidden_channels=hidden_channels,\n",
        "        num_layers=num_layers,\n",
        "        dropout=dropout,\n",
        "        use_timestamp_encoding=not disable_timestamp_encoding,\n",
        "    )\n",
        "    model = OilPriceTemporalGNN(config)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"min\", patience=max(5, patience // 3), factor=0.5\n",
        "    )\n",
        "    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n",
        "\n",
        "    history = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        optimizer,\n",
        "        scheduler=scheduler,\n",
        "        max_epochs=epochs,\n",
        "        early_stopping=early_stopping,\n",
        "    )\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    criterion = nn.MSELoss()\n",
        "    model.eval()\n",
        "    all_true: List[torch.Tensor] = []\n",
        "    all_pred: List[torch.Tensor] = []\n",
        "    test_losses: List[float] = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(device)\n",
        "            preds = model(batch)\n",
        "            target = batch.y.to(device).view_as(preds)\n",
        "            loss = criterion(preds, target)\n",
        "            all_true.append(target.cpu())\n",
        "            all_pred.append(preds.cpu())\n",
        "            test_losses.append(loss.item())\n",
        "\n",
        "    if not all_true or not all_pred:\n",
        "        raise ValueError(\"Test loader produced no samples. Check dataset configuration.\")\n",
        "\n",
        "    test_loss = float(torch.tensor(test_losses).mean().item())\n",
        "    test_metrics = compute_regression_metrics(torch.cat(all_true), torch.cat(all_pred))\n",
        "\n",
        "    history_records = [\n",
        "        {\n",
        "            \"epoch\": entry.epoch,\n",
        "            \"train_loss\": entry.train_loss,\n",
        "            \"val_loss\": entry.val_loss,\n",
        "            \"val_mae\": entry.val_metrics.mae,\n",
        "            \"val_rmse\": entry.val_metrics.rmse,\n",
        "            \"val_r2\": entry.val_metrics.r2,\n",
        "        }\n",
        "        for entry in history\n",
        "    ]\n",
        "    metrics_dict = {\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_mae\": test_metrics.mae,\n",
        "        \"test_rmse\": test_metrics.rmse,\n",
        "        \"test_r2\": test_metrics.r2,\n",
        "        \"num_snapshots\": len(dataset),\n",
        "        \"train_range\": dataset.start_timestamp.isoformat(),\n",
        "        \"test_range\": dataset.end_timestamp.isoformat(),\n",
        "    }\n",
        "\n",
        "    if output_dir is not None:\n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(parents=True, exist_ok=True)\n",
        "        history_path = output_path / \"training_history.json\"\n",
        "        metrics_path = output_path / \"test_metrics.json\"\n",
        "        with history_path.open(\"w\", encoding=\"utf-8\") as fp:\n",
        "            json.dump(history_records, fp, indent=2)\n",
        "        with metrics_path.open(\"w\", encoding=\"utf-8\") as fp:\n",
        "            json.dump(metrics_dict, fp, indent=2)\n",
        "        print(f\"Training history saved to {history_path}\")\n",
        "        print(f\"Test metrics saved to {metrics_path}\")\n",
        "\n",
        "    return history_records, metrics_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example usage\n",
        "\n",
        "Uncomment and edit the following cell with the path to your snapshot metadata to launch training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example: run a full training job\n",
        "# history, metrics = run_training(\n",
        "#     \"snapshots.csv\",\n",
        "#     start_year=2015,\n",
        "#     end_year=2024,\n",
        "#     batch_size=16,\n",
        "#     epochs=150,\n",
        "#     output_dir=\"runs/oil-price-gnn\",\n",
        "# )\n",
        "# metrics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}